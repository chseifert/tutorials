{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning #\n",
    "Author: Christin Seifert, licensed under the Creative Commons Attribution 3.0 Unported License https://creativecommons.org/licenses/by/3.0/\n",
    "\n",
    "This is a tutorial for implementing a simple machine learning pipeline aimed at machine learning beginners. \n",
    "In this notebook we will\n",
    "* train classifiers to classify iris flowers\n",
    "* evaluate how well the classifiers do that in general\n",
    "* dig a little deeper on where they might have problems\n",
    "\n",
    "It is assumed that you have some general knowledge on \n",
    "* what a decision tree is and how it works\n",
    "* how the Naive Bayes classifier works\n",
    "* training and testing splits of data sets\n",
    "* evaluation measures for classification (namely accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First, we import all the python libraries we will need later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pythons scientific computing package and a random number generator\n",
    "import numpy as np\n",
    "import random\n",
    "# machine learning classifiers and metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# standard data sets in python\n",
    "from sklearn import datasets\n",
    "# create random train and test splits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# plotting tool\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's get the data, then and have a look at some examples. It seems that there is a lot of variation for some numbers there. Can you make a decision which number you see wih high confidence for each of the examples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = datasets.load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data,data.target,shuffle=True,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.7 4.4 1.5 0.4]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.4 3.2 1.3 0.2]]\n",
      "[0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "#show examples from data set\n",
    "#let's look at the first 5 examples\n",
    "print(X_train[1:5])\n",
    "print(y_train[1:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation\n",
    "We do not need to generate any features hear, because we already have a nice matrix with features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n",
      "(30, 4)\n"
     ]
    }
   ],
   "source": [
    "# investigate the size of the feature matrices\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have 120 data items for training and 30 for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Naive Bayes Classifier\n",
    "Now we are nearly ready to train our first classifier. One thing still needs to be said. Classification is a supervised machine learning task. This means, we give the classifier a feature vector together with the desired output (the target). The targets were also loaded from the original data set and reside in the vector $y_{train}$. Putting things together, the classifier gets a matrix, which contains one row for each image and as many columns as we have features. And it also gets a vector of targets, that is as long as we have images. Thus the number of rows in $X_{train}$ is equal to the length of $y_{train}$. Isn't this neat?\n",
    "\n",
    "Now we finally can train our first model (a model is a trained classifer). The scikit learn library in python uses standard interfaces to all classifiers. This means, no matter which classifier you want to use, the functions you have to call are always named the same (but they might have different parameters). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the model with standard parameters\n",
    "clf_nb = MultinomialNB()\n",
    "# train the model\n",
    "clf_nb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Naive Bayes classifier\n",
    "Ok, nice. We have trained a model. In the code, the model is called `clf_nb`. But, is it a good model? To answer this, we need to evaluate the model on data it has not yet seen, that is on `X_test` and the respective labels `y_test`. \n",
    "\n",
    "We do this in two steps:\n",
    "\n",
    "1. We ask the classifier about its opinion by only giving it the test data (without the labels). This step is called **prediction**. We store the results in a vector `y_test_pred_nb`. \n",
    "\n",
    "2. We count how often the classifier's predictions are the same as the correct labels. This step is called **evaluaton**. The counting is already conveniently implemented in the library, so we only need to call a function `accuracy_score()` which returns us the ratio of correct predictions and total items. If you multiply this ratio by 100 you get a value that can be interpreted as \"the classifier is ... percent correct on the test data\".\n",
    "\n",
    "Thus, we can conclude, the classifier has an accuracy of approximately 90%. Or in other words, it misclassifies 10% of the examples. Is this good or bad? Has it learned something? What if we got a value of 50%. Would this be good? \n",
    "\n",
    "Whether it has learned _something_ can be answered quite easily. We could simply compared it to random guessing. There are 3 classes in the data set. In the test set, there is an equal amount of examples for each class. Or in other words, the examples are uniformly distributed over the classes. You could easily check this by inspecting `y_test`. If the classifier would randomly guess, which digit it sees, it would have a 33% chance of getting it right. So, it has learned quite a lot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "# make predictions with the NB classifier\n",
    "y_test_pred_nb = clf_nb.predict(X_test);\n",
    "a_nb = accuracy_score(y_test, y_test_pred_nb);\n",
    "print(a_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the decision tree classifier\n",
    "We train the decision tree classifier in a similar manner as we trained the Naive Bayes classifier. Note, that the function calls are equivalent.\n",
    "\n",
    "_Note: you might notice, that training of a decision tree can take some seconds._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_dt = DecisionTreeClassifier();\n",
    "clf_dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the decision tree classifier\n",
    "Now, let's see how well this model performs on the test set. \n",
    "\n",
    "It achieves an accuracy of about 100%, thus getting no examples wrong. This seems a bit better than the Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# make predictions with the decision tree classifier\n",
    "y_test_pred_dt = clf_dt.predict(X_test)\n",
    "a_dt = accuracy_score(y_test, y_test_pred_dt)\n",
    "print(a_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More detailed error analysis\n",
    "Can we find out more about the mistakes both models still make? If we could, we could probably find ways to improve it. Or it might also be the case that we might find errors in the underlying data (e.g. mislabeled images, images that do not contain digits at all). The latter case is in this example rather unlikely, since this data set has been studied already for a long time and by many different researchers and practicioners. \n",
    "\n",
    "### Confusion matrices\n",
    "One thing we could ask is which digits get often confused with one another. Or more generally, which classes often get confused? We can easily asses this, since we have the predictions and the true labels. So, for each digit we just have to count how often label $l$ in the ground truth is predicted as label $k$. We display this in matrix form, this matrix is called _class confusion matrix_ $C$. Entry $(i,j)$ in this matrix holds the count of how often the target $i$ was predicted as $j$. \n",
    "\n",
    "The strength of the confusion (i.e., the total number of misclassified examples) is indicated with a color in the respective cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the confusion matrices for both classifiers\n",
    "cm_nb = confusion_matrix(y_test, y_test_pred_nb);\n",
    "cm_dt = confusion_matrix(y_test, y_test_pred_dt);\n",
    "\n",
    "# plot the confusion matrices nicely\n",
    "plt.subplot(1, 2, 1)    \n",
    "plt.title('Decision Tree', fontsize=16)\n",
    "plt.imshow(cm_dt, interpolation='nearest',cmap=plt.cm.binary);\n",
    "plt.tight_layout();\n",
    "plt.colorbar();\n",
    "plt.ylabel('True label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.xticks(np.arange(3));\n",
    "plt.yticks(np.arange(3));\n",
    "\n",
    "plt.subplot(1, 2, 2) \n",
    "plt.title('Naive Bayes', fontsize=16)\n",
    "plt.imshow(cm_nb, interpolation='nearest',cmap=plt.cm.binary);\n",
    "plt.tight_layout();\n",
    "plt.colorbar();\n",
    "plt.ylabel('True label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.xticks(np.arange(3));\n",
    "plt.yticks(np.arange(3));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both plots show a nice dark diagonal. This indicates that most of the examples are predicted correctly (as we know from the accuracy measures). TBD: some more detailed conclusion.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "We have seen a very basic machine learning pipeline. We trained two different classifiers on the same data set and compared them. There are, of course as always ;-) many more things one could try, some of them are:\n",
    "\n",
    "* have a detailed look a the images that were misclassified\n",
    "* use more sophisticated features than just pixel values\n",
    "* try different classifiers\n",
    "* distort the test images and see how robust the classifiers are to noisy input.\n",
    "\n",
    "### Take-Aways\n",
    "1. A classifier needs feature vectors as input, so the input data has first to be transformed in a suitable format.\n",
    "1. Always train and evaluate on different data set splits.\n",
    "1. Accuracy alone is not a helpful measure, you need to compare it to something, at least the random baseline.\n",
    "1. Confusion matrices are a handy tool to pin-point the errors.\n",
    "\n",
    "That's all for today. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
